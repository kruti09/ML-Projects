{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook performs sentiment analysis on restaurant reviews.\n",
        "It uses GloVe embeddings and an LSTM model with PyTorch.\n",
        "The process includes data loading, preprocessing, model definition, training, and evaluation.\n"
      ],
      "metadata": {
        "id": "7qjbUX7hAWUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "!pip install scipy==1.13.1 numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRQeVfqZ4720",
        "outputId": "0707be4e-e3e6-4229-ad53-6c2b16d26fde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart the runtime after installing libraries. This is often necessary in Colab\n",
        "# to ensure that the newly installed packages are used.\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "BM-phiJp5AHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the gensim library\n",
        "!pip install gensim\n",
        "import gensim.downloader as api\n",
        "glove_vectors = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZrMepWa5trF",
        "outputId": "96161f5e-7a4d-4cf4-d699-8b5a2ed0ad60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.3.3\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xx796PscpRmI"
      },
      "outputs": [],
      "source": [
        "# Import pandas for data manipulation and numpy for numerical operations\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('RestaurantReview')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o_ISiXppZmE",
        "outputId": "5d96270e-a404-4591-e15d-0d223b98dfaa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at RestaurantReview\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from Google Drive into a pandas DataFrame\n",
        "df = pd.read_csv('RestaurantReview/MyDrive/pytorch practice notebooks/RestaurantsReview.csv')"
      ],
      "metadata": {
        "id": "NxdfUGuvpcVq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LiV8mxG_r9oh",
        "outputId": "c2c86d05-00c5-48e0-dd77-6c8bb180ce29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aeeac32c-b5cc-4e82-a559-9c8d9f7c92f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeeac32c-b5cc-4e82-a559-9c8d9f7c92f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aeeac32c-b5cc-4e82-a559-9c8d9f7c92f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aeeac32c-b5cc-4e82-a559-9c8d9f7c92f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bf10bf2d-1256-44fb-acb3-6cc991308e7b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf10bf2d-1256-44fb-acb3-6cc991308e7b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bf10bf2d-1256-44fb-acb3-6cc991308e7b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \" Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 996,\n        \"samples\": [\n          \"They were excellent.\",\n          \"Your servers suck, wait, correction, our server Heimer sucked.\",\n          \"Will be back again!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Liked\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the column ' Review' to 'Review' to remove leading space\n",
        "df.rename(columns={' Review':'Review'}, inplace=True)"
      ],
      "metadata": {
        "id": "wsE0phH5D5oJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where the 'Review' column is empty after splitting into words\n",
        "df1 = df.drop(df[df['Review'].astype(str).apply(lambda x: len(x.split()) == 0 )].index)"
      ],
      "metadata": {
        "id": "ZK_77cF8uArU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform one-hot encoding on the 'Liked' column\n",
        "df2 = pd.get_dummies(df1, columns = ['Liked'])"
      ],
      "metadata": {
        "id": "9XJmKUlrDtFN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the one-hot encoded columns for clarity\n",
        "df2.rename(columns={'Liked_0':'NotLiked', 'Liked_1':'Liked'}, inplace=True)"
      ],
      "metadata": {
        "id": "iaRTMEmFGFFY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace boolean values (False, True) with integers (0, 1)\n",
        "df2.replace([False, True],[0,1], inplace=True)"
      ],
      "metadata": {
        "id": "B2IPsnwkGU9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05ce1e4-8dfb-437f-ed67-5701b313ee09"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-e4d0d5402d56>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df2.replace([False, True],[0,1], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the torch library\n",
        "import re\n",
        "import torch"
      ],
      "metadata": {
        "id": "14gauoyB1k8p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to convert text to GloVe embeddings\n",
        "def text_to_embedding(text):\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  text = str(text).lower()\n",
        "  embeddings = []\n",
        "  for word in text.split():\n",
        "    try:\n",
        "      embeddings.append(glove_vectors.get_vector(word))\n",
        "    except:\n",
        "      embeddings.append(np.zeros(100))\n",
        "  return torch.tensor(embeddings)"
      ],
      "metadata": {
        "id": "owMUmVNqzfBE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the text_to_embedding function to each review and store the results in a list\n",
        "word_level_sentence_embedding_list = []\n",
        "for text in df2['Review'].values:\n",
        "    word_level_sentence_embedding_list.append(text_to_embedding(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnJRAf7k2J5G",
        "outputId": "58bb0423-e289-4b68-bd20-9ea852578af6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-be9fea294f0b>:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  return torch.tensor(embeddings)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n"
      ],
      "metadata": {
        "id": "oyGeq9md3WLi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences of word embeddings to a fixed length (32)\n",
        "padded_inputs = pad_sequence(word_level_sentence_embedding_list, batch_first=True, padding_value=1)"
      ],
      "metadata": {
        "id": "32jlPq8K6uPE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an attention mask to indicate which parts of the padded sequences are real data\n",
        "# 1 indicates original data, 0 indicates padding\n",
        "attention_mask_list = []\n",
        "for i in range(len(word_level_sentence_embedding_list)):\n",
        "    attention_mask_list.append(torch.cat((torch.ones(len(word_level_sentence_embedding_list[i])), torch.zeros(32 - len(word_level_sentence_embedding_list[i])))))"
      ],
      "metadata": {
        "id": "gMbYv-8f84Z-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the columns representing the output (Liked and NotLiked)\n",
        "output_columns = ['NotLiked',\t'Liked']"
      ],
      "metadata": {
        "id": "qvgzZKkw9fxz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the output columns to a NumPy array of float32 type\n",
        "output_array = df2[output_columns].to_numpy(dtype='float32')"
      ],
      "metadata": {
        "id": "WQbYOVqK9wqc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the output array to a PyTorch tensor\n",
        "targets = torch.tensor(output_array)"
      ],
      "metadata": {
        "id": "Kg1KC7iR-Udy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "AkPrlX4f-u7U"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom Dataset class for the review data\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, padded_inputs, attention_mask_list,targets, is_test=False):\n",
        "        self.padded_inputs = padded_inputs\n",
        "        self.attention_mask_list = attention_mask_list\n",
        "        self.targets = targets\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.padded_inputs[index],self.attention_mask_list[index] ,self.targets[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.padded_inputs)"
      ],
      "metadata": {
        "id": "hSWN7rsM-eKG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the ReviewDataset\n",
        "dataset = ReviewDataset(padded_inputs, attention_mask_list, targets)"
      ],
      "metadata": {
        "id": "3ZukSDn6-1hm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import DataLoader and random_split from torch.utils.data\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "metadata": {
        "id": "4SQdIMGU-_gl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the size of the training and validation sets (90% for training)\n",
        "train_size =int(len(dataset)*0.9)\n",
        "valid_size = len(dataset) - train_size"
      ],
      "metadata": {
        "id": "308lGn1X_JiL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets randomly\n",
        "train_data, valid_data = random_split(dataset, [train_size, valid_size])"
      ],
      "metadata": {
        "id": "_OOL-nHb_L34"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 50"
      ],
      "metadata": {
        "id": "5UkLv58A_OiL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for the training data\n",
        "train_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=True)\n",
        "val_dl = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=8, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxMakfOS_Ras",
        "outputId": "9aa10967-4eac-4910-95f0-e0ca74e3641f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "O5h6vkY5_UWe"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate accuracy\n",
        "def accuracy(out, target):\n",
        "  _ , pred = torch.max(out, dim=1)\n",
        "  _ , max_index = torch.max(target,dim=1)\n",
        "  return torch.tensor(torch.eq(pred, max_index).sum().item()/len(pred))"
      ],
      "metadata": {
        "id": "A0mopddE_ZIF"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Review sentiment analysis model using an LSTM\n",
        "class Review(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lstm = nn.LSTM(100, 50, num_layers=1, batch_first=True, bidirectional=False)\n",
        "    self.linear1 = nn.Linear(50, 25)\n",
        "    self.linear2 = nn.Linear(25, 2)\n",
        "\n",
        "  def forward(self, xb, attention_mask):\n",
        "    out, (hn, _) = self.lstm(xb)\n",
        "    last_index_output = torch.argmin(attention_mask).item()-1\n",
        "    out = F.relu(out[:,last_index_output,:])\n",
        "    out = self.linear1(out)\n",
        "    out = self.linear2(out)\n",
        "    return out\n",
        "\n",
        "  def training_step(self, batch):\n",
        "    inputs, attention_mask, targets = batch\n",
        "    outputs = self(inputs, attention_mask)\n",
        "    probs = torch.sigmoid(outputs)\n",
        "    loss = F.binary_cross_entropy(probs, targets)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch):\n",
        "    inputs, attention_mask, targets = batch\n",
        "    outputs = self(inputs, attention_mask)\n",
        "    probs = torch.sigmoid(outputs)\n",
        "    loss = F.binary_cross_entropy(probs, targets)\n",
        "    acc = accuracy(probs, targets)\n",
        "    return{'valid_loss' : loss, 'valid_acc': acc}\n",
        "\n",
        "  def validation_epoch_end(self, outputs):\n",
        "    batch_losses = [x['valid_loss'] for x in outputs]\n",
        "    epoch_loss = torch.stack(batch_losses).mean()\n",
        "    batch_accs = [x['valid_acc'] for x in outputs]\n",
        "    epoch_acc = torch.stack(batch_accs).mean()\n",
        "    return{'valid_loss': epoch_loss.item() ,'valid_acc': epoch_acc.item()}\n",
        "\n",
        "  def epoch_end(self, epoch, result, epochs):\n",
        "    if ((epoch+1) % 1 == 0 or epoch == epochs-1):\n",
        "      print(\"Epoch [{}], val_loss: {:.4f}, train_loss: {:.4f}, val_acc: {:.4f}, lrs: {:.5f}\".format(epoch, result['valid_loss'], result['train_loss'], result['valid_acc'], result['lrs'][-1]))"
      ],
      "metadata": {
        "id": "ZhVRbKZ5I3uT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to evaluate the model on the validation set\n",
        "def evaluate(model, valid_loader):\n",
        "  outputs = [model.validation_step(batch) for batch in valid_loader]\n",
        "  return model.validation_epoch_end(outputs)"
      ],
      "metadata": {
        "id": "m1edkNvoJPYv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decorator to disable gradient calculation (for inference or getting learning rate)\n",
        "@torch.no_grad()\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "# Define a function to train the model using the one-cycle learning rate policy\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader,\n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    # Set up cutom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "urlXR74ullB0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Review model\n",
        "model = Review()"
      ],
      "metadata": {
        "id": "J9pFqqLgJfc6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters for training\n",
        "epochs = 15\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-4\n",
        "opt_func = torch.optim.Adam"
      ],
      "metadata": {
        "id": "CqSXhAQqmz_e"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "%%time\n",
        "history = fit_one_cycle(epochs, max_lr, model, train_dl, val_dl,\n",
        "                             grad_clip=grad_clip,\n",
        "                             weight_decay=weight_decay,\n",
        "                             opt_func=opt_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0VS9L6_m0iP",
        "outputId": "9e7cb0e5-ea66-48cf-c0db-cfb88b292490"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], val_loss: 0.6925, train_loss: 0.6937, val_acc: 0.4800, lrs: 0.00143\n",
            "Epoch [1], val_loss: 0.7027, train_loss: 0.6893, val_acc: 0.4900, lrs: 0.00426\n",
            "Epoch [2], val_loss: 0.6863, train_loss: 0.6927, val_acc: 0.5300, lrs: 0.00755\n",
            "Epoch [3], val_loss: 0.6813, train_loss: 0.6934, val_acc: 0.5600, lrs: 0.00970\n",
            "Epoch [4], val_loss: 0.6608, train_loss: 0.6189, val_acc: 0.6600, lrs: 0.00994\n",
            "Epoch [5], val_loss: 0.6099, train_loss: 0.5287, val_acc: 0.6700, lrs: 0.00950\n",
            "Epoch [6], val_loss: 0.6583, train_loss: 0.4643, val_acc: 0.6600, lrs: 0.00867\n",
            "Epoch [7], val_loss: 0.6198, train_loss: 0.4396, val_acc: 0.6700, lrs: 0.00750\n",
            "Epoch [8], val_loss: 0.5719, train_loss: 0.4192, val_acc: 0.7100, lrs: 0.00611\n",
            "Epoch [9], val_loss: 0.5523, train_loss: 0.3661, val_acc: 0.6900, lrs: 0.00463\n",
            "Epoch [10], val_loss: 0.5455, train_loss: 0.2932, val_acc: 0.6900, lrs: 0.00317\n",
            "Epoch [11], val_loss: 0.5498, train_loss: 0.3181, val_acc: 0.6900, lrs: 0.00188\n",
            "Epoch [12], val_loss: 0.5528, train_loss: 0.2792, val_acc: 0.7000, lrs: 0.00087\n",
            "Epoch [13], val_loss: 0.5482, train_loss: 0.2574, val_acc: 0.7000, lrs: 0.00022\n",
            "Epoch [14], val_loss: 0.5443, train_loss: 0.2672, val_acc: 0.7000, lrs: 0.00000\n",
            "CPU times: user 7.15 s, sys: 4.83 s, total: 12 s\n",
            "Wall time: 17.4 s\n"
          ]
        }
      ]
    }
  ]
}
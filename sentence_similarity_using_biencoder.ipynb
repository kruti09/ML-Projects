{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri8Kk0nUxG22"
      },
      "source": [
        "This script trains a Bi-Encoder model for Sentence Similarity using the biencoder dataset.\n",
        "\n",
        "The model is based on BERT and is trained using Cosine Similarity as the loss function.\n",
        "\n",
        "The script includes steps for data loading, preprocessing, model training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "128_uU59k5PU"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spcjUu-qxDuw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIydZGZQk6HQ"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability and set device\n",
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh6Hp-eHk__2"
      },
      "outputs": [],
      "source": [
        "# Authenticate with Hugging Face Hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxP6Mck-lDfw"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "from datasets import load_dataset\n",
        "datasets = load_dataset(\"PhilipMay/stsb_multi_mt\", \"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b837qB0ll83V"
      },
      "outputs": [],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pr4BXSOlWHE"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCm_YNUyS9sG"
      },
      "outputs": [],
      "source": [
        "# Define a function to normalize tensor range\n",
        "import torch\n",
        "\n",
        "def normalize_tensor_range(tensor, new_min=-1, new_max=1):\n",
        "\n",
        "    min_val = tensor.min()\n",
        "    max_val = tensor.max()\n",
        "\n",
        "    # Scale to [0, 1]\n",
        "    tensor_scaled = (tensor - min_val) / (max_val - min_val)\n",
        "\n",
        "    # Scale to [new_min, new_max]\n",
        "    tensor_normalized = tensor_scaled * (new_max - new_min) + new_min\n",
        "\n",
        "    return tensor_normalized\n",
        "\n",
        "# Example tensors\n",
        "labels = torch.tensor(datasets['train']['similarity_score'])\n",
        "valid_labels = torch.tensor(datasets['dev']['similarity_score'])\n",
        "test_labels = torch.tensor(datasets['test']['similarity_score'])\n",
        "\n",
        "\n",
        "# Normalize tensors to the range [-1, 1]\n",
        "normalized_labels = normalize_tensor_range(labels)\n",
        "valid_normalized_labels = normalize_tensor_range(valid_labels)\n",
        "test_normalized_labels = normalize_tensor_range(test_labels)\n",
        "\n",
        "print(f\"Normalized Tensor 1: {torch.mean(normalized_labels), torch.mean(valid_normalized_labels), torch.mean(test_normalized_labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVh5d3bdRCzw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bke00w0LQ_y4"
      },
      "outputs": [],
      "source": [
        "class biencoderDataset(Dataset):\n",
        "    \"\"\"\n",
        "      A custom dataset class for the Bi-Encoder model.\n",
        "\n",
        "      Args:\n",
        "          sentence1: List of first sentences.\n",
        "          sentence2: List of second sentences.\n",
        "          normalized_labels: Normalized similarity scores.\n",
        "          tokenizer: The tokenizer to use.\n",
        "      \"\"\"\n",
        "    def __init__(self, sentence1, sentence2, normalized_labels , tokenizer):\n",
        "        self.all_input_id1 = []\n",
        "        self.all_input_id2 = []\n",
        "        self.all_attn_masks1 = []\n",
        "        self.all_attn_masks2 = []\n",
        "        self.normalized_labels = normalized_labels\n",
        "\n",
        "        for i, j in zip(sentence1, sentence2):\n",
        "            tokenized_sentence1 = tokenizer(i, padding='longest')\n",
        "            tokenized_sentence2 = tokenizer(j, padding='longest')\n",
        "            self.all_input_id1.append(tokenized_sentence1['input_ids'])\n",
        "            self.all_input_id2.append(tokenized_sentence2['input_ids'])\n",
        "            self.all_attn_masks1.append(tokenized_sentence1['attention_mask'])\n",
        "            self.all_attn_masks2.append(tokenized_sentence2['attention_mask'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_input_id1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.all_input_id1[idx]), torch.tensor(self.all_attn_masks1[idx]), torch.tensor(self.all_input_id2[idx]),torch.tensor(self.all_attn_masks2[idx]), self.normalized_labels[idx].item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BxFaL22U8VR"
      },
      "outputs": [],
      "source": [
        "train_dataset = biencoderDataset(datasets['train']['sentence1'], datasets['train']['sentence2'],normalized_labels, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsUdX8B8YF8Y"
      },
      "outputs": [],
      "source": [
        "valid_dataset = biencoderDataset(datasets['dev']['sentence1'], datasets['dev']['sentence2'],valid_normalized_labels, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU4ld1zfYKuq"
      },
      "outputs": [],
      "source": [
        "test_dataset = biencoderDataset(datasets['test']['sentence1'], datasets['test']['sentence2'],test_normalized_labels, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDiMmIlBV7L6"
      },
      "outputs": [],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sob9seHHU0h7"
      },
      "outputs": [],
      "source": [
        "class DataCollator:\n",
        "        def __init__(self, tokenizer):\n",
        "            self.tokenizer = tokenizer\n",
        "\n",
        "        def pad_tensors(self, tensors, padding_value=0):\n",
        "\n",
        "            return torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True, padding_value=padding_value)\n",
        "\n",
        "        def __call__(self, data):\n",
        "            output_dict = {'input_ids': [f[0] for f in data] + [f[2] for f in data],\n",
        "                           'attention_mask': [f[1] for f in data] + [f[3] for f in data],\n",
        "                           'labels': [f[4] for f in data]}\n",
        "            output_dict['all_input_ids'] = self.pad_tensors(output_dict['input_ids'],\n",
        "                                                        padding_value=self.tokenizer.pad_token_id)\n",
        "            output_dict['input_ids_1'] = output_dict['all_input_ids'][:len(data)]\n",
        "            output_dict['input_ids_2'] = output_dict['all_input_ids'][len(data):]\n",
        "            output_dict['labels'] = torch.tensor(output_dict['labels'])\n",
        "            output_dict['all_attention_mask'] = self.pad_tensors(output_dict['attention_mask'], padding_value=0)\n",
        "            output_dict['attention_mask_1'] = output_dict['all_attention_mask'][:len(data)]\n",
        "            output_dict['attention_mask_2'] = output_dict['all_attention_mask'][len(data):]\n",
        "            return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6bbbVonZ3iU"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollator(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_XMcmwqZn4w"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64, collate_fn=data_collator, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdIafya7_elF"
      },
      "outputs": [],
      "source": [
        "for i in train_dataloader:\n",
        "  print(i)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWDR1hzqYnmJ"
      },
      "outputs": [],
      "source": [
        "valid_dataloader = DataLoader(valid_dataset, batch_size=64, collate_fn=data_collator)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, collate_fn=data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjTj1Z3rNCIq"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDqpGtiYzSUS"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbCwFRQRzax1"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def pairwise_angle_sim(x, y):\n",
        "    \"\"\"\n",
        "    Computes the absolute normalized angle distance. See :class:`~sentence_transformers.losses.AnglELoss`\n",
        "    or https://arxiv.org/abs/2309.12871v1 for more information.\n",
        "\n",
        "    Args:\n",
        "        x (Tensor): The first tensor.\n",
        "        y (Tensor): The second tensor.\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Vector with res[i] = angle_sim(a[i], b[i])\n",
        "    \"\"\"\n",
        "    a, b = torch.chunk(x, 2, dim=1)\n",
        "    c, d = torch.chunk(y, 2, dim=1)\n",
        "\n",
        "    z = torch.sum(c**2 + d**2, dim=1, keepdim=True)\n",
        "    re = (a * c + b * d) / z\n",
        "    im = (b * c - a * d) / z\n",
        "\n",
        "    dz = torch.sum(a**2 + b**2, dim=1, keepdim=True) ** 0.5\n",
        "    dw = torch.sum(c**2 + d**2, dim=1, keepdim=True) ** 0.5\n",
        "    re /= dz / dw\n",
        "    im /= dz / dw\n",
        "\n",
        "    norm_angle = torch.sum(torch.concat((re, im), dim=1), dim=1)\n",
        "    return torch.abs(norm_angle)\n",
        "\n",
        "\n",
        "class CoSENTLoss(torch.nn.Module):\n",
        "  def __init__(self, scale: float = 20.0) -> None:\n",
        "      super().__init__()\n",
        "      self.scale = scale\n",
        "\n",
        "  def forward(self, scores, labels):\n",
        "\n",
        "      scores = scores * self.scale\n",
        "      scores = scores[:, None] - scores[None, :]\n",
        "\n",
        "      # label matrix indicating which pairs are relevant\n",
        "      labels = labels[:, None] < labels[None, :]\n",
        "      labels = labels.float()\n",
        "\n",
        "      # mask out irrelevant pairs so they are negligible after exp()\n",
        "      scores = scores - (1 - labels) * 1e12\n",
        "\n",
        "      # append a zero as e^0 = 1\n",
        "      scores = torch.cat((torch.zeros(1).to(scores.device), scores.view(-1)), dim=0)\n",
        "      loss = torch.logsumexp(scores, dim=0)\n",
        "\n",
        "      return loss\n",
        "\n",
        "\n",
        "def train(epochs, lr, model, train_dataloader, valid_dataloader, opt_func=torch.optim.Adam):\n",
        "  history = []\n",
        "  optimizer = opt_func(model.parameters(), lr)\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    for batch in tqdm(train_dataloader):\n",
        "      sentence_embeddings1 = []\n",
        "      sentence_embeddings2 = []\n",
        "      input_ids1 = batch['input_ids_1'].to(device)\n",
        "      attention_mask1 = batch['attention_mask_1'].to(device)\n",
        "\n",
        "      input_ids2 = batch['input_ids_2'].to(device)\n",
        "      attention_mask2 = batch['attention_mask_2'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      outputs1 = model(input_ids=input_ids1, attention_mask=attention_mask1)\n",
        "      outputs2 = model(input_ids=input_ids2, attention_mask=attention_mask2)\n",
        "      token_embeddings1 = outputs1.last_hidden_state\n",
        "      token_embeddings2 = outputs2.last_hidden_state\n",
        "\n",
        "      # unsqueeze attention to make it as same dimension as token embeddings\n",
        "      attention_mask1_unsqueezed = attention_mask1.unsqueeze(-1)\n",
        "      # unsqueeze attention multipliplied bt token embeddings to make zero where attention mask is zero\n",
        "      token_embeddings1_masked = torch.mul(token_embeddings1, attention_mask1_unsqueezed)\n",
        "      # take the sum of token embeddings and divide by attention mask count to take the avergae of only tokens which have attention mask 1\n",
        "      sentence_embeddings1 = torch.sum(token_embeddings1_masked, dim=1) / torch.sum(attention_mask1, dim=1, keepdim=True)\n",
        "\n",
        "      # unsqueeze attention to make it as same dimension as token embeddings\n",
        "      attention_mask2_unsqueezed = attention_mask2.unsqueeze(-1)\n",
        "      # unsqueeze attention multipliplied bt token embeddings to make zero where attention mask is zero\n",
        "      token_embeddings2_masked = torch.mul(token_embeddings2, attention_mask2_unsqueezed)\n",
        "      # take the sum of token embeddings and divide by attention mask count to take the avergae of only tokens which have attention mask 1\n",
        "      sentence_embeddings2 = torch.sum(token_embeddings2_masked, dim=1) / torch.sum(attention_mask2, dim=1, keepdim=True)\n",
        "\n",
        "      normalized_tensor1 = F.normalize(sentence_embeddings1, p=2, dim=1)\n",
        "      normalized_tensor2 = F.normalize(sentence_embeddings2, p=2, dim=1)\n",
        "      output_dot_product = pairwise_angle_sim(normalized_tensor1, normalized_tensor2)\n",
        "      # output_dot_product = torch.nn.functional.cosine_similarity(normalized_tensor1 , normalized_tensor2, dim=1)\n",
        "      # loss = torch.nn.MSELoss()(output_dot_product, labels)\n",
        "      # loss = 1 - output_dot_product.mean()\n",
        "      # loss = torch.mean(torch.abs(labels - output_dot_product))\n",
        "      # print(\"output_dot_product\", output_dot_product)\n",
        "      # print(\"labels\", labels)\n",
        "      loss = CoSENTLoss()(output_dot_product, labels)\n",
        "      # print(\"output_dot_product\", output_dot_product)\n",
        "      # angle_loss = AnglELoss(loss)(output_dot_product, labels)\n",
        "      # print(\"labels\", labels)\n",
        "      # print(\"loss\", loss.item())\n",
        "      train_losses.append(loss)\n",
        "      loss.backward() #calculate gradients\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      # print(train_losses)\n",
        "    total_loss = torch.stack(train_losses).mean().item()\n",
        "    # print('epoc_training_loss', total_loss)\n",
        "    # history.append(total_loss)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in tqdm(valid_dataloader):\n",
        "        sentence_embeddings1 = []\n",
        "        sentence_embeddings2 = []\n",
        "        input_ids1 = batch['input_ids_1'].to(device)\n",
        "        attention_mask1 = batch['attention_mask_1'].to(device)\n",
        "\n",
        "        input_ids2 = batch['input_ids_2'].to(device)\n",
        "        attention_mask2 = batch['attention_mask_2'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs1 = model(input_ids=input_ids1, attention_mask=attention_mask1)\n",
        "        outputs2 = model(input_ids=input_ids2, attention_mask=attention_mask2)\n",
        "        token_embeddings1 = outputs1.last_hidden_state\n",
        "        token_embeddings2 = outputs2.last_hidden_state\n",
        "\n",
        "        # unsqueeze attention to make it as same dimension as token embeddings\n",
        "        attention_mask1_unsqueezed = attention_mask1.unsqueeze(-1)\n",
        "        # unsqueeze attention multipliplied bt token embeddings to make zero where attention mask is zero\n",
        "        token_embeddings1_masked = torch.mul(token_embeddings1, attention_mask1_unsqueezed)\n",
        "        # take the sum of token embeddings and divide by attention mask count to take the avergae of only tokens which have attention mask 1\n",
        "        sentence_embeddings1 = torch.sum(token_embeddings1_masked, dim=1) / torch.sum(attention_mask1, dim=1, keepdim=True)\n",
        "\n",
        "        # unsqueeze attention to make it as same dimension as token embeddings\n",
        "        attention_mask2_unsqueezed = attention_mask2.unsqueeze(-1)\n",
        "        # unsqueeze attention multipliplied bt token embeddings to make zero where attention mask is zero\n",
        "        token_embeddings2_masked = torch.mul(token_embeddings2, attention_mask2_unsqueezed)\n",
        "        # take the sum of token embeddings and divide by attention mask count to take the avergae of only tokens which have attention mask 1\n",
        "        sentence_embeddings2 = torch.sum(token_embeddings2_masked, dim=1) / torch.sum(attention_mask2, dim=1, keepdim=True)\n",
        "\n",
        "        normalized_tensor1 = F.normalize(sentence_embeddings1, p=2, dim=1)\n",
        "        normalized_tensor2 = F.normalize(sentence_embeddings2, p=2, dim=1)\n",
        "\n",
        "        output_dot_product = torch.nn.functional.cosine_similarity(normalized_tensor1, normalized_tensor2, dim=1)\n",
        "        # print(\"output_dot_product\", output_dot_product)\n",
        "        # print(\"labels\", labels)\n",
        "        # loss = torch.nn.MSELoss()(output_dot_product, labels)\n",
        "        # loss = 1 - output_dot_product.mean()\n",
        "        loss = torch.mean(torch.abs(labels - output_dot_product))\n",
        "        # print(\"loss\", loss.item())\n",
        "        valid_losses.append(loss)\n",
        "        total_valid_loss = torch.stack(valid_losses).mean().item()\n",
        "    print('epoch_training_loss: {}, epoch_validation_loss: {}'.format(total_loss, total_valid_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH4nuamVbuXr"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained BERT model\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqTKgmhiCKRd"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "epochs = 20\n",
        "lr = 0.00001\n",
        "history = train(epochs, lr, model, train_dataloader, valid_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk-ONMbZgcdI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('sentence-similarity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNKnCjdRg0vU"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'sentence-similarity/My Drive/pytorch practice notebooks/ssm/model.pth')  # Change the path as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcLrRzUEQD2H"
      },
      "outputs": [],
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N368hi5Cnuox"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "state_dict = torch.load('sentence-similarity/My Drive/pytorch practice notebooks/ssm/model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX49d31jn711"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev2Z8SrFlllj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_Uk30rr8cOu"
      },
      "outputs": [],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpUCNBCjSGRR"
      },
      "outputs": [],
      "source": [
        "# Evaluating the saved model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch in test_dataloader:\n",
        "    sentence_embeddings1 = []\n",
        "    sentence_embeddings2 = []\n",
        "    input_ids1 = batch['input_ids_1'].to(device)\n",
        "    attention_mask1 = batch['attention_mask_1'].to(device)\n",
        "\n",
        "    input_ids2 = batch['input_ids_2'].to(device)\n",
        "    attention_mask2 = batch['attention_mask_2'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "\n",
        "    outputs1 = model(input_ids=input_ids1, attention_mask=attention_mask1)\n",
        "    outputs2 = model(input_ids=input_ids2, attention_mask=attention_mask2)\n",
        "    token_embeddings1 = outputs1.last_hidden_state\n",
        "    token_embeddings2 = outputs2.last_hidden_state\n",
        "\n",
        "    # unsqueeze attention to make it as same dimension as token embeddings\n",
        "    attention_mask1_unsqueezed = attention_mask1.unsqueeze(-1)\n",
        "    # unsqueeze attention multipliplied bt token embeddings to make zero where attention mask is zero\n",
        "    token_embeddings1_masked = torch.mul(token_embeddings1, attention_mask1_unsqueezed)\n",
        "    # take the sum of token embeddings and divide by attention mask count to take the avergae of only tokens which have attention mask 1\n",
        "    sentence_embeddings1 = torch.sum(token_embeddings1_masked, dim=1) / torch.sum(attention_mask1, dim=1, keepdim=True)\n",
        "\n",
        "    # unsqueeze attention to make it as same dimension as token embeddings\n",
        "    attention_mask2_unsqueezed = attention_mask2.unsqueeze(-1)\n",
        "    # unsqueeze attention multipliplied bt token embeddings to make zero where attention mask is zero\n",
        "    token_embeddings2_masked = torch.mul(token_embeddings2, attention_mask2_unsqueezed)\n",
        "    # take the sum of token embeddings and divide by attention mask count to take the avergae of only tokens which have attention mask 1\n",
        "    sentence_embeddings2 = torch.sum(token_embeddings2_masked, dim=1) / torch.sum(attention_mask2, dim=1, keepdim=True)\n",
        "\n",
        "    normalized_tensor1 = F.normalize(sentence_embeddings1, p=2, dim=1)\n",
        "    normalized_tensor2 = F.normalize(sentence_embeddings2, p=2, dim=1)\n",
        "\n",
        "    output_dot_product = torch.nn.functional.cosine_similarity(normalized_tensor1, normalized_tensor2, dim=1)\n",
        "    print(\"output_dot_product\", output_dot_product)\n",
        "    print(\"labels\", labels)\n",
        "    loss = torch.nn.MSELoss()(output_dot_product, labels)\n",
        "    print(\"loss\", loss.item())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBcBOGRBkyo8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
